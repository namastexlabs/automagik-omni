name: PR Tests

on:
  pull_request:
    branches: [main, dev]
    types: [opened, synchronize, reopened]
  push:
    branches: [dev]

permissions:
  contents: read
  pull-requests: write
  issues: write
  checks: write

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ["3.12"]
    
    # Removed PostgreSQL service - using SQLite for CI tests to avoid Docker Hub issues
    # services:
    #   postgres:
    #     image: postgres:15-alpine
    #     ...

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            libpq-dev \
            python3-dev

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[test,discord]"  # Install test + discord dependencies
          pip install pytest-xdist  # For parallel test execution

      - name: Set up environment variables
        run: |
          # Use SQLite for CI tests to avoid Docker Hub authentication issues
          mkdir -p data
          echo "DATABASE_URL=sqlite:///data/test.db" >> $GITHUB_ENV
          echo "AUTOMAGIK_OMNI_API_KEY=${{ secrets.TEST_API_KEY || 'dummy-key' }}" >> $GITHUB_ENV
          echo "PYTHONPATH=$GITHUB_WORKSPACE" >> $GITHUB_ENV
          echo "CI=true" >> $GITHUB_ENV

      - name: Initialize database
        run: |
          python -c "
          from sqlalchemy import create_engine
          from src.db.models import Base
          import os
          # Create SQLite database
          engine = create_engine(os.environ['DATABASE_URL'])
          Base.metadata.create_all(engine)
          print('SQLite database initialized successfully')
          "

      - name: Run tests with coverage
        id: test
        run: |
          # Run tests with coverage in parallel for faster execution
          pytest tests/ \
            -v \
            --tb=short \
            --color=yes \
            --cov=src \
            --cov-report=term-missing:skip-covered \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=json:coverage.json \
            --cov-report=term > pytest-coverage.txt \
            --junitxml=test-results.xml \
            --maxfail=5 \
            --disable-warnings \
            -n auto \
            -k "not test_bearer_token_validation and not test_add_command_help" \
            || TEST_FAILED=$?

          # Store test result
          if [ "${TEST_FAILED}" != "" ]; then
            echo "test_failed=true" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "test_failed=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.python-version }}
          path: |
            test-results.xml
            htmlcov/
            pytest-coverage.txt
            coverage.xml
            coverage.json
          retention-days: 7

      - name: Get target branch coverage for comparison
        if: github.event_name == 'pull_request' && always()
        id: target-coverage
        run: |
          # Get the target branch name (usually 'main' or 'dev')
          TARGET_BRANCH="${{ github.base_ref }}"
          echo "TARGET_BRANCH=$TARGET_BRANCH" >> $GITHUB_OUTPUT

          # Try to get coverage from target branch
          echo "Attempting to get coverage from target branch: $TARGET_BRANCH"

          # Check if we're in a git repository context
          if [ -d .git ]; then
            # Store current branch
            CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)

            # Fetch target branch
            git fetch origin $TARGET_BRANCH:$TARGET_BRANCH || echo "Could not fetch target branch"

            # Try to get target branch coverage by checking out and running tests
            if git checkout $TARGET_BRANCH 2>/dev/null; then
              echo "Successfully checked out target branch $TARGET_BRANCH"

              # Quick coverage check on target branch (only if deps are already installed)
              if pytest tests/ --cov=src --cov-report=term --maxfail=1 -q -x &>/dev/null; then
                TARGET_COVERAGE=$(pytest tests/ --cov=src --cov-report=term 2>/dev/null | grep -oP 'TOTAL.*?(\d+)%' | grep -oP '\d+%' | head -1 || echo "0%")
                echo "TARGET_COVERAGE=$TARGET_COVERAGE" >> $GITHUB_OUTPUT
                echo "Target branch coverage: $TARGET_COVERAGE"
              else
                echo "TARGET_COVERAGE=unknown" >> $GITHUB_OUTPUT
                echo "Could not determine target branch coverage"
              fi

              # Return to current branch
              git checkout $CURRENT_BRANCH
            else
              echo "TARGET_COVERAGE=unknown" >> $GITHUB_OUTPUT
              echo "Could not checkout target branch for coverage comparison"
            fi
          else
            # Not in a git context, use baseline
            echo "Not in git repository, using baseline coverage"
            echo "TARGET_COVERAGE=85%" >> $GITHUB_OUTPUT
          fi

      - name: Beautiful Coverage Comment
        if: github.event_name == 'pull_request' && always()
        uses: MishaKav/pytest-coverage-comment@main
        with:
          pytest-coverage-path: ./pytest-coverage.txt
          junitxml-path: ./test-results.xml
          unique-id-for-comment: coverage-${{ matrix.python-version }}
          title: "ğŸ“Š Coverage Report (Python ${{ matrix.python-version }}) vs ${{ steps.target-coverage.outputs.TARGET_BRANCH }}"
          badge-title: "Coverage"
          hide-badge: false
          hide-report: false
          create-new-comment: false
          hide-comment: false
          report-only-changed-files: false
          remove-link-from-badge: false

      - name: Coverage Comparison Summary
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            try {
              const fs = require('fs');
              const path = require('path');

              if (!context.issue || !context.issue.number) {
                console.log('Not in a pull request context, skipping coverage comment');
                return;
              }

              let currentCoverage = 'unknown';
              let coverageDetails = '';

              const coverageFile = path.join(process.env.GITHUB_WORKSPACE || '.', 'pytest-coverage.txt');
              console.log('Looking for coverage file at:', coverageFile);

              if (fs.existsSync(coverageFile)) {
                const coverageContent = fs.readFileSync(coverageFile, 'utf8');
                const coverageMatch = coverageContent.match(/TOTAL\s+\d+\s+\d+\s+(\d+)%/) ||
                                      coverageContent.match(/TOTAL.*?(\d+)%/);

                if (coverageMatch) {
                  currentCoverage = coverageMatch[1];
                  console.log('Found coverage:', currentCoverage + '%');
                }

                const lines = coverageContent.split('\n');
                const fileLines = lines.filter(line =>
                  line.includes('.py') &&
                  !line.startsWith('Name') &&
                  !line.startsWith('TOTAL') &&
                  line.trim().length > 0
                );

                if (fileLines.length > 0) {
                  const significantFiles = fileLines
                    .map(line => {
                      const parts = line.trim().split(/\s+/);
                      if (parts.length >= 4) {
                        const fileName = parts[0];
                        const coverage = parts[parts.length - 1];
                        return { fileName, coverage };
                      }
                      return null;
                    })
                    .filter(file => file && file.coverage && file.coverage.includes('%'))
                    .slice(0, 5);

                  if (significantFiles.length > 0) {
                    coverageDetails = '\n### ğŸ“ Key Files Coverage:\n' +
                      significantFiles.map(file => `- \`${file.fileName}\`: ${file.coverage}`).join('\n');
                  }
                }
              } else {
                console.log('Coverage file not found');
              }

              const targetCoverage = '${{ steps.target-coverage.outputs.TARGET_COVERAGE }}' || '85%';
              const targetBranch = '${{ steps.target-coverage.outputs.TARGET_BRANCH }}' || 'dev';

              let comparisonMessage = '';

              if (currentCoverage !== 'unknown') {
                const targetPercent = parseInt((targetCoverage || '85%').replace('%', ''));
                const currentPercent = parseInt(currentCoverage);
                const difference = currentPercent - targetPercent;

                let changeEmoji = 'ğŸ“Š';
                let changeText = '';

                if (Number.isInteger(difference) && difference > 0) {
                  changeEmoji = 'ğŸ“ˆ';
                  changeText = `+${difference}% âœ…`;
                } else if (Number.isInteger(difference) && difference < 0) {
                  changeEmoji = 'ğŸ“‰';
                  changeText = `${difference}% âš ï¸`;
                } else {
                  changeEmoji = 'ğŸ”„';
                  changeText = 'no change âœ…';
                }

                const tableRow1 = '| Branch | Coverage | Change |';
                const tableRow2 = '|--------|----------|--------|';
                const tableRow3 = `| **${targetBranch}** (baseline) | ${targetCoverage} | - |`;
                const tableRow4 = `| **Current PR** | ${currentCoverage}% | ${changeText} |`;
                comparisonMessage = `## ${changeEmoji} Coverage Report\n\n${tableRow1}\n${tableRow2}\n${tableRow3}\n${tableRow4}\n\n${coverageDetails}`;
              } else {
                comparisonMessage = '## ğŸ“Š Coverage Report\n\n**Coverage data not available**\n\n> Note: Coverage file may not have been generated or could not be parsed.';
              }

              const body = comparisonMessage;

              try {
                const { data: comments } = await github.rest.issues.listComments({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                });

                const existingComment = comments.find(comment =>
                  comment.user.type === 'Bot' &&
                  comment.body.includes('Coverage Report')
                );

                if (existingComment) {
                  await github.rest.issues.updateComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    comment_id: existingComment.id,
                    body: body
                  });
                  console.log('Updated existing coverage comment');
                } else {
                  await github.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: context.issue.number,
                    body: body
                  });
                  console.log('Created new coverage comment');
                }
              } catch (apiError) {
                console.log('Could not post comment:', apiError.message);
              }

            } catch (error) {
              console.error('Coverage comparison error:', error);
              console.log('Step continuing despite error');
            }

      - name: Upload coverage to Codecov
        if: always()
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-${{ matrix.python-version }}
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Test Report
        if: always()
        uses: dorny/test-reporter@v1
        continue-on-error: true
        with:
          name: Test Results (Python ${{ matrix.python-version }})
          path: test-results.xml
          reporter: java-junit
          fail-on-error: false
          path-replace-backslashes: false
          list-suites: all
          list-tests: failed
          max-annotations: 10

      - name: Enhanced Test Results Comment
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Get test summary
            let testSummary = 'âœ… All tests passed!';
            let statusEmoji = 'âœ…';

            if ('${{ steps.test.outputs.test_failed }}' === 'true') {
              testSummary = 'âŒ Some tests failed';
              statusEmoji = 'âŒ';
            }

            // Parse test results with enhanced details
            let testDetails = '';
            let executionTime = '';

            try {
              if (fs.existsSync('test-results.xml')) {
                const xmlContent = fs.readFileSync('test-results.xml', 'utf8');
                const testsMatch = xmlContent.match(/tests="(\d+)"/);
                const failuresMatch = xmlContent.match(/failures="(\d+)"/);
                const errorsMatch = xmlContent.match(/errors="(\d+)"/);
                const skippedMatch = xmlContent.match(/skipped="(\d+)"/);
                const timeMatch = xmlContent.match(/time="([^"]+)"/);

                if (testsMatch) {
                  const tests = parseInt(testsMatch[1]);
                  const failures = failuresMatch ? parseInt(failuresMatch[1]) : 0;
                  const errors = errorsMatch ? parseInt(errorsMatch[1]) : 0;
                  const skipped = skippedMatch ? parseInt(skippedMatch[1]) : 0;
                  const passed = tests - failures - errors - skipped;

                  if (timeMatch) {
                    const timeSeconds = parseFloat(timeMatch[1]);
                    executionTime = timeSeconds > 60
                      ? `â±ï¸ **Execution Time:** ${Math.floor(timeSeconds/60)}m ${Math.round(timeSeconds%60)}s`
                      : `â±ï¸ **Execution Time:** ${timeSeconds.toFixed(2)}s`;
                  }

                  const passRate = ((passed / tests) * 100).toFixed(1);

                  testDetails = `
            ## ğŸ§ª Test Execution Summary

            | Status | Count | Percentage |
            |--------|-------|------------|
            | âœ… **Passed** | **${passed}** | **${passRate}%** |
            | âŒ Failed | ${failures} | ${((failures/tests)*100).toFixed(1)}% |
            | ğŸ”¥ Errors | ${errors} | ${((errors/tests)*100).toFixed(1)}% |
            | â­ï¸ Skipped | ${skipped} | ${((skipped/tests)*100).toFixed(1)}% |
            | ğŸ“ **Total** | **${tests}** | **100%** |

            ${executionTime}`;
                }
              }
            } catch (e) {
              console.log('Could not parse test results:', e);
              testDetails = '\nğŸ” Test details could not be parsed from XML output.';
            }

            const body = `## ${statusEmoji} Test Execution Report

            ### Python ${{ matrix.python-version }} â€¢ ${testSummary}

            ${testDetails}

            ---

            ğŸ“‹ **Workflow Details:**
            - ğŸ **Python Version:** ${{ matrix.python-version }}
            - ğŸ–¥ï¸ **Runner OS:** ${{ runner.os }}
            - ğŸ“ **Commit:** \`${{ github.sha }}\`
            - ğŸ”— [**View Full Logs**](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

            > ğŸ’¡ **Note:** Detailed coverage report available in separate comment below`;

            // Find existing test comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const testComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Test Execution Report')
            );

            if (testComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: testComment.id,
                body: body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Check test status
        if: steps.test.outputs.test_failed == 'true'
        run: |
          echo "âŒ Tests failed! Please fix the failing tests before merging."
          exit 1

  test-ui:
    name: UI Tests (Playwright)
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: resources/ui/package-lock.json

      - name: Install UI dependencies
        working-directory: resources/ui
        run: |
          if [ -f package-lock.json ]; then
            npm ci --legacy-peer-deps
          else
            echo "package-lock.json not found, using npm install"
            npm install --legacy-peer-deps
          fi

      - name: Install Playwright browsers
        working-directory: resources/ui
        run: npx playwright install chromium --with-deps

      - name: Set up Python for backend
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install backend dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e .

      - name: Start backend services
        run: |
          mkdir -p data
          export DATABASE_URL=sqlite:///data/test.db
          export AUTOMAGIK_OMNI_API_KEY=test-api-key-for-playwright
          export TEST_API_KEY=test-api-key-for-playwright
          python -c "
          from sqlalchemy import create_engine
          from src.db.models import Base
          import os
          engine = create_engine(os.environ['DATABASE_URL'])
          Base.metadata.create_all(engine)
          "
          # Start backend in background
          nohup python -m uvicorn src.api.app:app --host 0.0.0.0 --port 8882 > backend.log 2>&1 &
          echo $! > backend.pid
          # Wait for backend to be ready
          for i in {1..30}; do
            if curl -s http://localhost:8882/health > /dev/null; then
              echo "Backend is ready"
              break
            fi
            echo "Waiting for backend... ($i/30)"
            sleep 2
          done

      - name: Run Playwright tests (headless)
        working-directory: resources/ui
        run: npm run test:e2e
        env:
          CI: true
          TEST_API_KEY: test-api-key-for-playwright

      - name: Upload Playwright test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: resources/ui/playwright-report/
          retention-days: 7

      - name: Upload Playwright test videos
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-videos
          path: resources/ui/test-results/
          retention-days: 7

      - name: Stop backend services
        if: always()
        run: |
          if [ -f backend.pid ]; then
            kill $(cat backend.pid) || true
            rm backend.pid
          fi

  lint:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install linting dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff mypy

      - name: Run Ruff linter
        id: ruff
        run: |
          ruff check src/ tests/ --output-format=github || RUFF_FAILED=$?
          if [ "${RUFF_FAILED}" != "" ]; then
            echo "ruff_failed=true" >> $GITHUB_OUTPUT
          else
            echo "ruff_failed=false" >> $GITHUB_OUTPUT
          fi
          # Fail the step if linting issues found (enforce quality gates)
          exit ${RUFF_FAILED:-0}

      - name: Run Ruff formatter check
        id: ruff-format
        run: |
          ruff format --check src/ tests/ || FORMAT_FAILED=$?
          if [ "${FORMAT_FAILED}" != "" ]; then
            echo "format_failed=true" >> $GITHUB_OUTPUT
            echo "âŒ Code formatting issues found. Run 'ruff format src/ tests/' to fix."
          else
            echo "format_failed=false" >> $GITHUB_OUTPUT
          fi
          # Fail the step if formatting issues found (enforce quality gates)
          exit ${FORMAT_FAILED:-0}

      - name: Comment lint results on PR
        if: github.event_name == 'pull_request' && (steps.ruff.outputs.ruff_failed == 'true' || steps.ruff-format.outputs.format_failed == 'true')
        uses: actions/github-script@v7
        with:
          script: |
            let message = '## âš ï¸ Code Quality Issues Found\n\n';
            
            if ('${{ steps.ruff.outputs.ruff_failed }}' === 'true') {
              message += 'âŒ **Linting issues detected**\n';
              message += 'Run `ruff check src/ tests/ --fix` to auto-fix some issues.\n\n';
            }
            
            if ('${{ steps.ruff-format.outputs.format_failed }}' === 'true') {
              message += 'âŒ **Formatting issues detected**\n';
              message += 'Run `ruff format src/ tests/` to fix formatting.\n\n';
            }
            
            message += 'ğŸ“š [View workflow logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: message
            });

  all-checks-passed:
    name: All Checks Passed
    needs: [test, test-ui, lint]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Check results
        run: |
          if [ "${{ needs.test.result }}" != "success" ] || [ "${{ needs.test-ui.result }}" != "success" ] || [ "${{ needs.lint.result }}" != "success" ]; then
            echo "âŒ Some checks failed!"
            echo "Test result: ${{ needs.test.result }}"
            echo "UI test result: ${{ needs.test-ui.result }}"
            echo "Lint result: ${{ needs.lint.result }}"
            exit 1
          else
            echo "âœ… All checks passed successfully!"
          fi
